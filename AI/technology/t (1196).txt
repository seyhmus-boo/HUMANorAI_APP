This presentation explores the experimental challenges inherent in leveraging big data within modern industries. While the potential benefits – improved efficiency, predictive modelling, and enhanced decision-making – are widely acknowledged, realizing this potential is hampered by significant methodological hurdles.  We focus on three key areas:  Firstly, the inherent complexity of data heterogeneity poses significant challenges for data integration and cleaning, demanding sophisticated preprocessing techniques and robust validation strategies. Secondly, the sheer volume of data necessitates computationally efficient algorithms and scalable infrastructure, raising concerns about resource allocation, energy consumption, and the potential for algorithmic bias amplified by scale.  Finally, the ethical considerations surrounding data privacy, security, and potential for discriminatory outcomes demand rigorous experimental design and careful consideration of responsible data governance frameworks.  This presentation will illustrate these challenges with examples drawn from diverse industrial sectors, highlighting ongoing research into innovative solutions and emphasizing the crucial role of experimental design in mitigating risks and maximizing the potential of big data applications.  We will conclude by outlining key future research directions necessary to overcome these limitations and unlock the full transformative potential of big data.