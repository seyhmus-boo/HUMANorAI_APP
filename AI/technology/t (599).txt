Artificial Intelligence (AI) and Machine Learning (ML) have witnessed unprecedented growth, permeating various sectors and revolutionizing numerous applications.  However, despite their remarkable successes, the experimental validation and rigorous testing of AI/ML systems remain fraught with challenges. This paper focuses on these critical experimental hurdles, moving beyond celebratory narratives of technological advancement to critically examine the limitations of current methodologies.  We address the inherent complexities involved in designing robust and unbiased experiments, highlighting issues such as data bias and its propagation through models, the difficulty in establishing meaningful ground truth in many real-world applications, and the challenges of generalizability across different domains and contexts. Furthermore, we explore the limitations of existing evaluation metrics, often insufficient to capture the multifaceted nature of AI/ML performance and their real-world impact.  Ultimately, this paper argues for a more critical and rigorous approach to experimentation in AI/ML, emphasizing the need for improved methodologies and the development of more comprehensive evaluation frameworks to ensure the responsible and effective deployment of these powerful technologies.